{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSkRdkIVilFw",
        "outputId": "f50cb163-2d2d-41d5-bc43-a233e23d5c5d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvtuRISuhk9b",
        "outputId": "0bfb20ab-4742-422b-c195-41e07770a58c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PQqlhbkvhbJ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
        "from transformers import BertTokenizer,AutoModel,AdamW,AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import json\n",
        "import gc\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tzQrEEythbKJ"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    input_path = '/content/drive/MyDrive/ccf/'\n",
        "    model_path = 'hfl/chinese-roberta-wwm-ext' #  nghuyong/ernie-2.0-large-en studio-ousia/luke-large\n",
        "    scheduler = 'cosine'  # ['linear', 'cosine']\n",
        "    batch_scheduler = True\n",
        "    num_cycles = 0.5  # 1.5\n",
        "    num_warmup_steps = 0\n",
        "    max_input_length = 1024\n",
        "    epochs = 5  # 5\n",
        "    encoder_lr = 20e-6\n",
        "    decoder_lr = 20e-6\n",
        "    min_lr = 0.5e-6\n",
        "    eps = 1e-6\n",
        "    betas = (0.9, 0.999)\n",
        "    weight_decay = 0\n",
        "    num_fold = 5\n",
        "    batch_size = 20\n",
        "    seed = 1006\n",
        "    OUTPUT_DIR = '/content/drive/MyDrive/ccf/'\n",
        "    num_workers = 2\n",
        "    device='cuda'\n",
        "    print_freq = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything(CFG.seed)"
      ],
      "metadata": {
        "id": "mykwcZyypr1O"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrBpJ61KhbJ7"
      },
      "source": [
        "## 1. Read Data & EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "id": "69UrMW56hbJ9"
      },
      "outputs": [],
      "source": [
        "def read_jsonfile(file_name):\n",
        "    data = []\n",
        "    with open(file_name) as f:\n",
        "        for i in f.readlines():\n",
        "            data.append(json.loads(i))\n",
        "    return data\n",
        "\n",
        "train = pd.DataFrame(read_jsonfile(CFG.input_path + \"/train.json\"))\n",
        "#add = pd.read_csv('/content/drive/MyDrive/ccf/additional_train.csv')\n",
        "#train = pd.concat([train, add])\n",
        "test = pd.DataFrame(read_jsonfile(CFG.input_path + \"/testA.json\"))\n",
        "train['label_id'] = train['label_id'].apply(lambda x :int(x))\n",
        "train.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "jVY6fFsZhbJ_",
        "outputId": "d1db7e67-91af-4557-c146-01865733f361"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index                                id              title  \\\n",
              "0        0  538f267d2e6fba48b1286fb7f1499fe7  一种信号的发送方法及基站、用户设备   \n",
              "1        1  635a7d4b6358b6ff24a324bb871505db     一种5G通讯电缆故障监控系统   \n",
              "2        2  aaf98d6bfe1932cf1a262812ca59d1ba        一种测试方法及电子设备   \n",
              "3        3  ad49c9ba6412452d9b25071af702f4fb          天线方位角调节装置   \n",
              "4        4  ffa2d7617b3eac3a1d7df01e5bb515a2        光纤老化预测方法及装置   \n",
              "..     ...                               ...                ...   \n",
              "953    953  6af8c4c55c93ee38b8912db4576b3cfc        一种信息处理方法及装置   \n",
              "954    954  bc94427b0ae4c5a734ef7d32d6a1b9ea        一种适用于安防的广告机   \n",
              "955    955  2b1d9b24b86b2e49f842bd2c93cb865c      一种广告投放控制方法及装置   \n",
              "956    956  674baad2739c09bc9cc759322a0085c7      一种广告数据推荐方法和系统   \n",
              "957    957  94b8d5a69a04bc931bb2d65ea95fc9b2     一种基于大数据的广告推送系统   \n",
              "\n",
              "              assignee                                           abstract  \\\n",
              "0             华为技术有限公司  一种信号的发送方法及基站、用户设备。在一个子帧中为多个用户设备配置的参考信号的符号和数据的符...   \n",
              "1    中铁二十二局集团电气化工程有限公司  本发明公开了一种5G通讯电缆故障监控系统，包括信号采样模块、补偿反馈模块，所述信号采样模块对...   \n",
              "2         腾讯科技(北京)有限公司  本发明提供了一种测试方法及电子设备，该方法包括：基于选取的测试任务确定目标测试用例，根据所述...   \n",
              "3       武汉虹信通信技术有限责任公司  一种天线方位角调节装置，包括对向的两个8字形支架(101)、动力输入电机(102)、主动齿轮...   \n",
              "4         新华三大数据技术有限公司  本申请提供一种光纤老化预测方法及装置，所述方法包括：获取待测光纤模块可接收的光信号的告警阈值...   \n",
              "..                 ...                                                ...   \n",
              "953       腾讯科技(深圳)有限公司  本发明公开了一种信息处理方法，所述方法包括：第一进程获取来自多个查询请求端的多个数据请求，所...   \n",
              "954    靖江天元爱尔瑞电子科技有限公司  本实用新型公开了一种适用于安防的广告机，包括支撑架，支撑架的上端设置有显示屏，显示屏与壳体配...   \n",
              "955       阿里巴巴(中国)有限公司  本发明公开了一种广告投放控制方法及装置，以解决现有技术中基于地域定向的广告投放方式准确度较低...   \n",
              "956       北京奇艺世纪科技有限公司  本发明公开了一种广告数据推荐方法和系统。所述方法包括：接收到用户对目标广告数据的浏览请求后，...   \n",
              "957     浙江华坤道威数据科技有限公司  本发明公开了一种基于大数据的广告推送系统，包括用户信息采集模块、大数据采集模块、数据处理模块...   \n",
              "\n",
              "     label_id  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "..        ...  \n",
              "953        35  \n",
              "954        35  \n",
              "955        35  \n",
              "956        35  \n",
              "957        35  \n",
              "\n",
              "[958 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c4d19f9-8f7a-4545-91b0-50cfc9815e9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>assignee</th>\n",
              "      <th>abstract</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>538f267d2e6fba48b1286fb7f1499fe7</td>\n",
              "      <td>一种信号的发送方法及基站、用户设备</td>\n",
              "      <td>华为技术有限公司</td>\n",
              "      <td>一种信号的发送方法及基站、用户设备。在一个子帧中为多个用户设备配置的参考信号的符号和数据的符...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>635a7d4b6358b6ff24a324bb871505db</td>\n",
              "      <td>一种5G通讯电缆故障监控系统</td>\n",
              "      <td>中铁二十二局集团电气化工程有限公司</td>\n",
              "      <td>本发明公开了一种5G通讯电缆故障监控系统，包括信号采样模块、补偿反馈模块，所述信号采样模块对...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>aaf98d6bfe1932cf1a262812ca59d1ba</td>\n",
              "      <td>一种测试方法及电子设备</td>\n",
              "      <td>腾讯科技(北京)有限公司</td>\n",
              "      <td>本发明提供了一种测试方法及电子设备，该方法包括：基于选取的测试任务确定目标测试用例，根据所述...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ad49c9ba6412452d9b25071af702f4fb</td>\n",
              "      <td>天线方位角调节装置</td>\n",
              "      <td>武汉虹信通信技术有限责任公司</td>\n",
              "      <td>一种天线方位角调节装置，包括对向的两个8字形支架(101)、动力输入电机(102)、主动齿轮...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ffa2d7617b3eac3a1d7df01e5bb515a2</td>\n",
              "      <td>光纤老化预测方法及装置</td>\n",
              "      <td>新华三大数据技术有限公司</td>\n",
              "      <td>本申请提供一种光纤老化预测方法及装置，所述方法包括：获取待测光纤模块可接收的光信号的告警阈值...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>953</td>\n",
              "      <td>6af8c4c55c93ee38b8912db4576b3cfc</td>\n",
              "      <td>一种信息处理方法及装置</td>\n",
              "      <td>腾讯科技(深圳)有限公司</td>\n",
              "      <td>本发明公开了一种信息处理方法，所述方法包括：第一进程获取来自多个查询请求端的多个数据请求，所...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>954</td>\n",
              "      <td>bc94427b0ae4c5a734ef7d32d6a1b9ea</td>\n",
              "      <td>一种适用于安防的广告机</td>\n",
              "      <td>靖江天元爱尔瑞电子科技有限公司</td>\n",
              "      <td>本实用新型公开了一种适用于安防的广告机，包括支撑架，支撑架的上端设置有显示屏，显示屏与壳体配...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>955</td>\n",
              "      <td>2b1d9b24b86b2e49f842bd2c93cb865c</td>\n",
              "      <td>一种广告投放控制方法及装置</td>\n",
              "      <td>阿里巴巴(中国)有限公司</td>\n",
              "      <td>本发明公开了一种广告投放控制方法及装置，以解决现有技术中基于地域定向的广告投放方式准确度较低...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>956</td>\n",
              "      <td>674baad2739c09bc9cc759322a0085c7</td>\n",
              "      <td>一种广告数据推荐方法和系统</td>\n",
              "      <td>北京奇艺世纪科技有限公司</td>\n",
              "      <td>本发明公开了一种广告数据推荐方法和系统。所述方法包括：接收到用户对目标广告数据的浏览请求后，...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>957</td>\n",
              "      <td>94b8d5a69a04bc931bb2d65ea95fc9b2</td>\n",
              "      <td>一种基于大数据的广告推送系统</td>\n",
              "      <td>浙江华坤道威数据科技有限公司</td>\n",
              "      <td>本发明公开了一种基于大数据的广告推送系统，包括用户信息采集模块、大数据采集模块、数据处理模块...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c4d19f9-8f7a-4545-91b0-50cfc9815e9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c4d19f9-8f7a-4545-91b0-50cfc9815e9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c4d19f9-8f7a-4545-91b0-50cfc9815e9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcHSw4IShbJ_"
      },
      "source": [
        "### 1.1 Label Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "FBTH1j2ghbKA",
        "outputId": "83995e31-756a-4ca7-bfc8-c1e3fdde8673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb968a3550>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train.label_id.hist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.label_id.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaF42PzgdTIi",
        "outputId": "2ee154f0-b46e-4872-922e-0fd3938dd487"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    958.000000\n",
              "mean      11.140919\n",
              "std        9.325865\n",
              "min        0.000000\n",
              "25%        3.000000\n",
              "50%        8.000000\n",
              "75%       17.750000\n",
              "max       35.000000\n",
              "Name: label_id, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOEhmIyyhbKB"
      },
      "source": [
        "### 1.2 Input Length Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "xKobJHMZhbKB",
        "outputId": "57002777-47b6-455e-abb7-951022fec7ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb9659aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train['title_len'] = train['title'].apply(lambda x: len(x))\n",
        "train['title_len'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['title_len'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4wfqaEeXDA",
        "outputId": "711f4920-9bde-4f36-b32c-69d6a5d57751"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    958.000000\n",
              "mean      16.423800\n",
              "std        6.028142\n",
              "min        2.000000\n",
              "25%       12.000000\n",
              "50%       16.000000\n",
              "75%       21.000000\n",
              "max       37.000000\n",
              "Name: title_len, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "seYqTDIPhbKC",
        "outputId": "23f96a01-38f8-4aa9-e14e-e466d39530a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb96366510>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train['assignee_len'] = train['assignee'].apply(lambda x: len(x))\n",
        "train['assignee_len'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['assignee_len'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsvY1v-zezA3",
        "outputId": "521b4651-4aaa-4c5d-e74d-f019f4af43fc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    958.000000\n",
              "mean      10.494781\n",
              "std        4.019216\n",
              "min        2.000000\n",
              "25%        8.000000\n",
              "50%       11.000000\n",
              "75%       13.000000\n",
              "max       31.000000\n",
              "Name: assignee_len, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wVL5eQa0hbKD",
        "outputId": "a624abd8-c57d-454b-f77e-8a95ff799e99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb962f7090>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train['abstract_len'] = train['abstract'].apply(lambda x: len(x))\n",
        "train['abstract_len'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['abstract_len'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXAxxqp8fLfH",
        "outputId": "1c07df0b-326b-424d-a91d-da739d15907e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    958.000000\n",
              "mean     254.092902\n",
              "std       52.885760\n",
              "min       59.000000\n",
              "25%      228.000000\n",
              "50%      271.000000\n",
              "75%      291.000000\n",
              "max      639.000000\n",
              "Name: abstract_len, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Ytd7IkCAhbKE",
        "outputId": "e5f7b03e-e354-409d-9a74-2cad1076a512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb963c1090>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train['input_text'] = train['title'] + train['assignee'] + train['abstract']\n",
        "train['input_text_len'] = train['input_text'].apply(lambda x: len(x))\n",
        "train['input_text_len'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8lG3vk5hbKE"
      },
      "source": [
        "结论：\n",
        "训练数据较小仅有900条数据，test数据〉2w条，典型小样本训练场景\n",
        "输入文本长度普遍在350个字以下，超过400的词很少\n",
        "label的分布也不是很均衡，可能存在较难样本学习不充分的情况"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFl40iz6hbKF",
        "outputId": "881a726c-c6c4-4d63-e862-fe1f813a81bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=5)\n",
        "for fold, (_, val_) in enumerate(skf.split(X=train, y=train.label_id, groups=train.label_id)):\n",
        "    train.loc[val_, \"fold\"] = int(fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFZZ6X7VhbKF",
        "outputId": "cdb2f318-938b-421f-ce34-c27e04685807"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fold  label_id\n",
              "0.0   2           544\n",
              "      10          298\n",
              "      0           172\n",
              "      7           150\n",
              "      8           116\n",
              "                 ... \n",
              "4.0   29            1\n",
              "      31            1\n",
              "      32            1\n",
              "      33            1\n",
              "      35            1\n",
              "Name: label_id, Length: 179, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train.groupby('fold')['label_id'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRIgdvPChbKG"
      },
      "source": [
        "## 2. Build model Input and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2TmyJC_hbKG"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self,df,tokenizer):\n",
        "        self.title = df['title'].values\n",
        "        self.assignee = df['assignee'].values\n",
        "        self.abstract = df['abstract'].values\n",
        "        self.label = df['label_id'].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sep_token = tokenizer.sep_token\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "    def __getitem__(self, item):\n",
        "        label = int(self.label[item])\n",
        "        title = self.title[item]\n",
        "        assignee = self.assignee[item]\n",
        "        abstract = self.abstract[item]\n",
        "        input_text =  title + self.sep_token + assignee + self.sep_token + abstract\n",
        "        inputs = self.tokenizer(input_text, truncation=True, max_length=400, padding='max_length')\n",
        "        return torch.as_tensor(inputs['input_ids'], dtype=torch.long), \\\n",
        "               torch.as_tensor(inputs['attention_mask'], dtype=torch.long), \\\n",
        "               torch.as_tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKCU5PeahbKH"
      },
      "source": [
        "## 3. Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JTytv2RhbKH",
        "outputId": "88ffbbcc-1ad6-459e-c56e-852e012b50ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('hfl/chinese-roberta-wwm-ext',num_labels=36)\n",
        "tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ukyVMxhbKH"
      },
      "source": [
        "## 4.Build train pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4yGGljShbKI"
      },
      "outputs": [],
      "source": [
        "def get_score(preds, gts):\n",
        "    return f1_score(preds, gts, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4Q6DGkohbKI"
      },
      "outputs": [],
      "source": [
        "def train_fn(train_loader, model, optimizer, epoch, scheduler, device):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        label = batch[2].to(device)\n",
        "        mask = batch[1].to(device)\n",
        "        input_ids = batch[0].to(device)\n",
        "        batch_size = label.size(0)\n",
        "        output = model(input_ids, mask, labels=label)\n",
        "        loss = output.loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 500)\n",
        "        optimizer.step()\n",
        "        global_step += 1\n",
        "        scheduler.step()\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f}  '\n",
        "                  'LR: {lr:.8f}  '\n",
        "                  .format(epoch + 1, step, len(train_loader),\n",
        "                          remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
        "                          loss=losses,\n",
        "                          grad_norm=grad_norm,\n",
        "                          lr=scheduler.get_lr()[0]))\n",
        "    return losses.avg\n",
        "\n",
        "def valid_fn(valid_loader, model, device):\n",
        "    losses = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    start = end = time.time()\n",
        "    for step, batch in enumerate(valid_loader):\n",
        "        label = batch[2].to(device)\n",
        "        mask = batch[1].to(device)\n",
        "        input_ids = batch[0].to(device)\n",
        "        batch_size = label.size(0)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids, mask, labels=label)\n",
        "        loss = output.loss\n",
        "        y_preds = output.logits.argmax(dim=-1)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "        labels.append(label.to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print('EVAL: [{0}/{1}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(step, len(valid_loader),\n",
        "                          loss=losses,\n",
        "                          remain=timeSince(start, float(step + 1) / len(valid_loader))))\n",
        "    predictions = np.concatenate(preds)\n",
        "    labels = np.concatenate(labels)\n",
        "    return losses.avg, predictions, labels\n",
        "\n",
        "\n",
        "def train_loop(fold, model, train_dataset, valid_dataset):\n",
        "    LOGGER.info(f\"========== training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # loader\n",
        "    # ====================================================\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    #model = Custom_Bert_Simple()\n",
        "    #model = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n",
        "    model.to(CFG.device)\n",
        "\n",
        "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "\n",
        "    optimizer_parameters = get_optimizer_params(model,\n",
        "                                                encoder_lr=CFG.encoder_lr,\n",
        "                                                decoder_lr=CFG.decoder_lr,\n",
        "                                                weight_decay=CFG.weight_decay)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
        "\n",
        "    # ====================================================\n",
        "    # scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        cfg.num_warmup_steps = cfg.num_warmup_steps * num_train_steps\n",
        "        if cfg.scheduler == 'linear':\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps,\n",
        "                num_cycles=cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    num_train_steps = int(len(train_dataset) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    # criterion = torch.nn.CrossEntropyLoss(ignore_index=- 1)\n",
        "\n",
        "    # criterion = LabelSmoothingLoss()\n",
        "    best_score = 0.\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, optimizer, epoch, scheduler, CFG.device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions, valid_labels = valid_fn(valid_loader, model, CFG.device)\n",
        "\n",
        "        # scoring\n",
        "        score = get_score(predictions, valid_labels)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f'Epoch {epoch + 1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch + 1} - Score: {score:.4f}')\n",
        "\n",
        "\n",
        "        if best_score < score:\n",
        "            best_score = score\n",
        "            best_predictions = predictions\n",
        "            LOGGER.info(f'Epoch {epoch + 1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                       CFG.OUTPUT_DIR + \"{}_best{}.pth\".format(CFG.model_path.replace('/', '_'),fold))\n",
        "\n",
        "\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    del scheduler, optimizer, model\n",
        "    return best_predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oQ5XGEnhbKJ"
      },
      "source": [
        "## 5.Build Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhZV-ZKshbKK"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcxdTETChbKK",
        "outputId": "f90e22a5-c55b-49c3-ca5c-aa7ee923eb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "===============lr_2e-05===============\n",
            "INFO:__main__:===============lr_2e-05===============\n",
            "===============seed_1006===============\n",
            "INFO:__main__:===============seed_1006===============\n",
            "===============total_epochs_5===============\n",
            "INFO:__main__:===============total_epochs_5===============\n",
            "===============num_warmup_steps_0===============\n",
            "INFO:__main__:===============num_warmup_steps_0===============\n"
          ]
        }
      ],
      "source": [
        "def get_logger(filename=CFG.OUTPUT_DIR+ 'train'):\n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "LOGGER.info('===============lr_{}==============='.format(CFG.encoder_lr))\n",
        "LOGGER.info('===============seed_{}==============='.format(CFG.seed))\n",
        "LOGGER.info('===============total_epochs_{}==============='.format(CFG.epochs))\n",
        "LOGGER.info('===============num_warmup_steps_{}==============='.format(CFG.num_warmup_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TRMLFrnhbKL",
        "outputId": "e7486b01-830b-4236-a232-a3d6411dd735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== training ==========\n",
            "INFO:__main__:========== training ==========\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/363] Elapsed 0m 2s (remain 15m 0s) Loss: 3.6682(3.6682) Grad: 10.7638  LR: 0.00002000  \n",
            "Epoch: [1][100/363] Elapsed 0m 47s (remain 2m 2s) Loss: 0.3283(1.5552) Grad: 3.1495  LR: 0.00001985  \n",
            "Epoch: [1][200/363] Elapsed 1m 31s (remain 1m 14s) Loss: 0.5031(0.9991) Grad: 14.2149  LR: 0.00001940  \n",
            "Epoch: [1][300/363] Elapsed 2m 17s (remain 0m 28s) Loss: 0.3651(0.7701) Grad: 13.5713  LR: 0.00001868  \n",
            "Epoch: [1][362/363] Elapsed 2m 45s (remain 0m 0s) Loss: 0.5432(0.6894) Grad: 8.3376  LR: 0.00001810  \n",
            "EVAL: [0/46] Elapsed 0m 0s (remain 0m 24s) Loss: 1.0636(1.0636) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.6894  avg_val_loss: 0.5272  time: 178s\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.6894  avg_val_loss: 0.5272  time: 178s\n",
            "Epoch 1 - Score: 0.2813\n",
            "INFO:__main__:Epoch 1 - Score: 0.2813\n",
            "Epoch 1 - Save Best Score: 0.2813 Model\n",
            "INFO:__main__:Epoch 1 - Save Best Score: 0.2813 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [45/46] Elapsed 0m 12s (remain 0m 0s) Loss: 0.1415(0.5272) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/363] Elapsed 0m 0s (remain 3m 40s) Loss: 0.3873(0.3873) Grad: 2.1642  LR: 0.00001809  \n",
            "Epoch: [2][100/363] Elapsed 0m 45s (remain 1m 57s) Loss: 0.1284(0.2015) Grad: 9.5585  LR: 0.00001695  \n",
            "Epoch: [2][200/363] Elapsed 1m 29s (remain 1m 12s) Loss: 0.0295(0.2085) Grad: 0.4939  LR: 0.00001561  \n",
            "Epoch: [2][300/363] Elapsed 2m 14s (remain 0m 27s) Loss: 0.2590(0.1945) Grad: 2.2189  LR: 0.00001411  \n",
            "Epoch: [2][362/363] Elapsed 2m 41s (remain 0m 0s) Loss: 0.2931(0.1896) Grad: 6.1640  LR: 0.00001311  \n",
            "EVAL: [0/46] Elapsed 0m 0s (remain 0m 20s) Loss: 1.2757(1.2757) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.1896  avg_val_loss: 0.5060  time: 175s\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.1896  avg_val_loss: 0.5060  time: 175s\n",
            "Epoch 2 - Score: 0.4055\n",
            "INFO:__main__:Epoch 2 - Score: 0.4055\n",
            "Epoch 2 - Save Best Score: 0.4055 Model\n",
            "INFO:__main__:Epoch 2 - Save Best Score: 0.4055 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [45/46] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0223(0.5060) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3][0/363] Elapsed 0m 0s (remain 3m 37s) Loss: 0.1178(0.1178) Grad: 6.5225  LR: 0.00001309  \n",
            "Epoch: [3][100/363] Elapsed 0m 45s (remain 1m 57s) Loss: 0.2613(0.1235) Grad: 4.5392  LR: 0.00001141  \n",
            "Epoch: [3][200/363] Elapsed 1m 29s (remain 1m 12s) Loss: 0.0246(0.1327) Grad: 1.0557  LR: 0.00000969  \n",
            "Epoch: [3][300/363] Elapsed 2m 14s (remain 0m 27s) Loss: 0.1279(0.1274) Grad: 1.6498  LR: 0.00000798  \n",
            "Epoch: [3][362/363] Elapsed 2m 41s (remain 0m 0s) Loss: 0.0190(0.1214) Grad: 0.3250  LR: 0.00000694  \n",
            "EVAL: [0/46] Elapsed 0m 0s (remain 0m 19s) Loss: 1.1919(1.1919) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.1214  avg_val_loss: 0.4837  time: 175s\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.1214  avg_val_loss: 0.4837  time: 175s\n",
            "Epoch 3 - Score: 0.4719\n",
            "INFO:__main__:Epoch 3 - Score: 0.4719\n",
            "Epoch 3 - Save Best Score: 0.4719 Model\n",
            "INFO:__main__:Epoch 3 - Save Best Score: 0.4719 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [45/46] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0146(0.4837) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4][0/363] Elapsed 0m 0s (remain 3m 47s) Loss: 0.0126(0.0126) Grad: 0.2520  LR: 0.00000692  \n",
            "Epoch: [4][100/363] Elapsed 0m 45s (remain 1m 57s) Loss: 0.0155(0.0832) Grad: 0.1667  LR: 0.00000533  \n",
            "Epoch: [4][200/363] Elapsed 1m 29s (remain 1m 12s) Loss: 0.0138(0.0859) Grad: 0.1584  LR: 0.00000388  \n",
            "Epoch: [4][300/363] Elapsed 2m 14s (remain 0m 27s) Loss: 0.1539(0.0862) Grad: 2.3258  LR: 0.00000261  \n",
            "Epoch: [4][362/363] Elapsed 2m 41s (remain 0m 0s) Loss: 0.0196(0.0838) Grad: 0.2606  LR: 0.00000193  \n",
            "EVAL: [0/46] Elapsed 0m 0s (remain 0m 19s) Loss: 1.1729(1.1729) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0838  avg_val_loss: 0.4870  time: 175s\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.0838  avg_val_loss: 0.4870  time: 175s\n",
            "Epoch 4 - Score: 0.5064\n",
            "INFO:__main__:Epoch 4 - Score: 0.5064\n",
            "Epoch 4 - Save Best Score: 0.5064 Model\n",
            "INFO:__main__:Epoch 4 - Save Best Score: 0.5064 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [45/46] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0153(0.4870) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5][0/363] Elapsed 0m 0s (remain 3m 40s) Loss: 0.1152(0.1152) Grad: 4.0198  LR: 0.00000192  \n",
            "Epoch: [5][100/363] Elapsed 0m 45s (remain 1m 57s) Loss: 0.0129(0.0547) Grad: 0.1314  LR: 0.00000103  \n",
            "Epoch: [5][200/363] Elapsed 1m 29s (remain 1m 12s) Loss: 0.0123(0.0676) Grad: 0.1807  LR: 0.00000040  \n",
            "Epoch: [5][300/363] Elapsed 2m 14s (remain 0m 27s) Loss: 0.0155(0.0730) Grad: 0.4399  LR: 0.00000006  \n",
            "Epoch: [5][362/363] Elapsed 2m 41s (remain 0m 0s) Loss: 0.0875(0.0716) Grad: 3.3004  LR: 0.00000000  \n",
            "EVAL: [0/46] Elapsed 0m 0s (remain 0m 19s) Loss: 1.1973(1.1973) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0716  avg_val_loss: 0.4866  time: 175s\n",
            "INFO:__main__:Epoch 5 - avg_train_loss: 0.0716  avg_val_loss: 0.4866  time: 175s\n",
            "Epoch 5 - Score: 0.5014\n",
            "INFO:__main__:Epoch 5 - Score: 0.5014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL: [45/46] Elapsed 0m 12s (remain 0m 0s) Loss: 0.0110(0.4866) \n"
          ]
        }
      ],
      "source": [
        "fold = 0\n",
        "tr_data = train[train['fold']!=fold].reset_index(drop=True)\n",
        "va_data = train[train['fold']==fold].reset_index(drop=True)\n",
        "tr_dataset = TrainDataset(tr_data,tokenizer)\n",
        "va_dataset =TrainDataset(va_data,tokenizer)\n",
        "val_result = train_loop(fold, model,tr_dataset, va_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "YChdW-GfRVdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YQlpOUnhbKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bd465f-7024-48a2-9888-01fd09b703c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "521it [02:26,  3.56it/s]\n"
          ]
        }
      ],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.title = df['title'].values\n",
        "        self.assignee = df['assignee'].values\n",
        "        self.abstract = df['abstract'].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sep_token = tokenizer.sep_token\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        title = self.title[item]\n",
        "        assignee = self.assignee[item]\n",
        "        abstract = self.abstract[item]\n",
        "        input_text = title + self.sep_token + assignee + self.sep_token + abstract\n",
        "        inputs = self.tokenizer(input_text, truncation=True, max_length=400, padding='max_length')\n",
        "        return torch.as_tensor(inputs['input_ids'], dtype=torch.long), \\\n",
        "               torch.as_tensor(inputs['attention_mask'], dtype=torch.long)\n",
        "\n",
        "def infer(test_loader, model, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    probs = []\n",
        "    for step, batch in tqdm(enumerate(test_loader)):\n",
        "        mask = batch[1].to(device)\n",
        "        input_ids = batch[0].to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids=input_ids, attention_mask=mask)\n",
        "        logits = F.softmax(output.logits, dim=-1)\n",
        "        prob, y_preds = logits.max(dim=-1)\n",
        "        probs.append(prob.to('cpu').numpy())\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "\n",
        "    predictions = np.concatenate(preds)\n",
        "    probs = np.concatenate(probs)\n",
        "    return predictions, probs\n",
        "\n",
        "saved_path = CFG.OUTPUT_DIR + \"{}_best{}.pth\".format(CFG.model_path.replace('/', '_'),fold)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('hfl/chinese-roberta-wwm-ext', num_labels=36)\n",
        "tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext')\n",
        "model.load_state_dict(torch.load(saved_path)['model'])\n",
        "test_dataset = TestDataset(test, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                              batch_size=CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "results, probs = infer(test_dataloader, model, CFG.device)\n",
        "test['label'] = results\n",
        "test['probs'] = probs\n",
        "test = test[['id', 'label']]\n",
        "test.to_csv('submit_A.csv', index=None)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}